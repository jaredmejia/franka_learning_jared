import numpy as np
from scipy import special
import pickle
from argparse import Action
import pickle
import numpy as np

import os
import sys
import torch
from  scipy import special
from torch import embedding
from torchvision import transforms as T
from torchvision import models 
from torch import nn
from sklearn.neighbors import KDTree
#from models.model_loading import MODEL_LIST, load_pvr_model, preprocess_image
#from vision import load_model, load_transforms
from PIL import Image, ImageDraw

class KNNImage(object):
    def __init__(self, k, pickle_fn, vision_model, device='cuda:0'):
        with open(pickle_fn, 'rb') as f:
            paths = pickle.load(f)
        paths=paths['demos']
        actions = []
        representations = []
        img_paths = []
        for path in paths:
            actions.append(path['commands'])
            reps_l =[]
            for img_add in path['cam0c']:
                address= os.path.join('/home/vdean/franka_demo/logs/good_chopping_exps/'+str(path['traj_id']), img_add)
                tmp = Image.open(address)
                reps_l.append(np.array(crop_and_resize(tmp)).flatten())
                tmp.close()
            representations.append(reps_l)   
            img_paths.extend([os.path.join(path['traj_id'], fname) for fname in path['cam0c']])
            #representations.append(path['embeddings']) # not using jointstates

        self.representations = np.vstack(representations)
        self.actions = np.vstack(actions)
        self.img_paths = img_paths
        self.KDTree = KDTree(data=self.representations)
        self.vision_model = vision_model
        self.k = 3

    def predict(self, sample):
        
        #state = self.vision_model(torch.unsqueeze(sample['cam0c'], dim=0)).detach().numpy()
        #state = state.reshape([1, -1])
        ## state = np.hstack([sample['inputs'].reshape([1, -1]), state]) # not using jointstates
        state = crop_and_resize(sample['cam0c'])
        print(sample['audio'])
        state= np.array(state).flatten()
        print(state.sum())
        state = state.reshape([1, -1])
        knn_dis, knn_idx = self.KDTree.query(state, k=self.k)
        #print(knn_dis[0])
        #print(knn_dis[:5])
        return_action = self.actions[knn_idx[0][0]] ### TODO: works for k=1 only so far!!!
        print(knn_idx)
        print("Closest image:",self.img_paths[knn_idx[0][0]])

        actions = [self.actions[i] for i in knn_idx[0]]
        weights = [-1*(knn_dis[0][i]) for i in range(self.k)]
        weights = special.softmax(weights)
        return_action = np.zeros(7)
        for i in range(self.k):
            return_action += weights[i] * actions[i]

        return return_action
def crop_and_resize(img):
    #im1 = img.crop((50, 0, 450, 385))
    return img.resize((50, 50))

def _init_agent_from_config(config, device='cpu'):
    print("Loading KNNImage................")
    vision_model =  lambda x: x #load_model(config)
    # transforms = load_transforms(config)
    transforms = crop_and_resize
    knn_agent = KNNImage(config.knn.k, config.data.pickle_fn, vision_model)
    return knn_agent, transforms

def img_test(img_path, knn_agent, transforms, k=1):
    img = Image.open(img_path)
    img_tensor = transforms(img)
    state = knn_agent.vision_model(np.array(img_tensor).flatten())

    # device = 'cuda:0'
    # import yaml, sys, argparse, os, pickle
    # from utils import Namespace
    # with open(os.path.join('/home/gaoyue/dev/franka_learning/outputs/', 'knn_image', 'hydra.yaml'), 'r') as f:
    #     cfg = yaml.load(f, Loader=yaml.FullLoader)
    #     cfg = Namespace(cfg)
    # model = load_model(cfg)
    # model.to(device)

    # for p1, p2 in zip(knn_agent.vision_model.parameters(), model.parameters()):
    #     if p1.data.ne(p2.data).sum() > 0:
    #         print("false")
    # print('true')

    # state = np.hstack([np.array([[-0.15769309, -0.1116268,   0.18283216, -2.43667363,  0.01225936,  0.77048624, -0.60743096]]), state])
    knn_dis, knn_idx = knn_agent.KDTree.query(state, k=10)

    return knn_agent.img_paths[knn_idx[0][0]]
    # import pdb; pdb.set_trace()
    # np.mean(np.array([knn_agent.actions[i] for i in knn_idx[0]]), axis=0)
    # import pdb; pdb.set_trace()
    # return knn_idx


def load_and_annotate(path, vision_model, filename):
    im = Image.open(path)
    I1 = ImageDraw.Draw(im)

    big_font = ImageFont.truetype("/usr/share/fonts/truetype/freefont/FreeMono.ttf", 40)
    small_font = ImageFont.truetype("/usr/share/fonts/truetype/freefont/FreeMono.ttf", 20)

    I1.text((5, 5), vision_model, stroke_width=1, fill=(255, 0, 0), font=big_font)
    I1.text((5, HEIGHT-25), filename, fill=(255, 0, 0), font=small_font)
    return im
    
if __name__ == "__main__":
    # img_path = '/home/gaoyue/Desktop/cloud-dataset-inserting-v0/data/22-05-19-23-13-32/c0-818312070212-1653016412230.5496-color.jpeg'
    test_image_folder = "/home/gaoyue/Desktop/cloud-dataset-scooping-v0-part2/data/"
    test_images = ["22-05-05-17-20-20/c0-818312070212-1651785641073.2153-color.jpeg"]
    test_images = [test_image_folder + fname for fname in test_images]

    WIDTH = 640
    HEIGHT = 480

    import yaml, sys, argparse, os, pickle
    from PIL import Image, ImageDraw, ImageFont
    from utils import Namespace
    with open(os.path.join('/home/gaoyue/dev/franka_learning/outputs/', 'knn_image', 'hydra.yaml'), 'r') as f:
        cfg = yaml.load(f, Loader=yaml.FullLoader)
        cfg['data']['pickle_fn'] = "/home/gaoyue/Desktop/cloud-dataset-scooping-v0/parsed_with_embeddings_byol_robocloud.pkl"
        cfg = Namespace(cfg)

    # Load pickle with pre-computed embeddings
    # Edit agent.vision_model, agent.vision_model_path
    knn_agent, transforms = _init_agent_from_config(cfg)
    dataset_folder = os.path.join(os.path.dirname(cfg.data.pickle_fn), 'data')

    #new_im = Image.new('RGB', (WIDTH * len(images), HEIGHT))
    new_im = Image.new('RGB', (WIDTH * 2, HEIGHT))

    for img_path in test_images:
        test_img = load_and_annotate(img_path, "Test image", img_path)
        new_im.paste(test_img, (0, 0))
        x_offset = WIDTH
    
        closest_img = img_test(img_path, knn_agent, transforms)
        path = os.path.join(dataset_folder,closest_img)
        im = load_and_annotate(path, cfg.agent.vision_model, closest_img)
        
        new_im.paste(im, (x_offset,0))
        x_offset += WIDTH

        new_im.save('test.jpg')
        import pdb; pdb.set_trace()
